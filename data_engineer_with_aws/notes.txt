Data store on S3:
Song -> s3://udacity-dend/song_data
logs -> s3://udacity-dend/log_data

To properly read the logs
log metadata ->  s3://udacity-dend/log_json_path.json

Keep in mind that the udacity-dend bucket is situated in the us-west-2 region. 
If you're copying the dataset to Redshift located in us-east-1, remember 
to specify the region using the REGION keyword in the COPY command.

 The files are partitioned by the first three letters of each song's track ID.

song_data/A/B/C/TRABCEI128F424C983.json
song_data/A/A/B/TRAABJL12903CDCF1A.json

 {"num_songs": 1, 
 "artist_id": "ARJIE2Y1187B994AB7", 
 "artist_latitude": null, 
 "artist_longitude": null, 
 "artist_location": "", 
 "artist_name": "Line Renaud",
 "song_id": "SOUPIRU12A6D4FA1E1", 
 "title": "Der Kleine Dompfaff",
"duration": 152.92036, 
"year": 0}

The log files in the dataset you'll be working with are partitioned by year and month. 

log_data/2018/11/2018-11-12-events.json
log_data/2018/11/2018-11-13-events.json

In the context of this project, you will need the log_json_path.json file in the COPY command, 
which is responsible for loading the log data from S3 into the staging tables in Redshift. 
The log_json_path.json file tells Redshift how to interpret the JSON data and extract the relevant fields. 
This is essential for further processing and transforming the data into the desired analytics tables.


Fact Table
    songplays - records in event data associated with song plays i.e. records with page NextSong
        songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent


Dimension Tables
    users - users in the app
        user_id, first_name, last_name, gender, level
    songs - songs in music database
        song_id, title, artist_id, year, duration
    artists - artists in music database
        artist_id, name, location, latitude, longitude
    time - timestamps of records in songplays broken down into specific units
        start_time, hour, day, week, month, year, weekday   